# ğŸ†“ FREE LLM Setup - No Credit Card Required!

## The Problem

You want to use AI-powered sprint planning **without paying for API tokens**. Ollama works locally but not on Render (cloud hosting).

## âœ… Solution: Use Groq API (100% FREE!)

**Groq offers:**
- âœ… **FREE tier** - No credit card required
- âœ… **Fast inference** - Powered by their custom chips
- âœ… **Works on Render** - Cloud-based API
- âœ… **Generous limits** - Perfect for development/testing
- âœ… **Powerful models** - Llama 3.1 70B, Mixtral, and more

---

## ğŸš€ Quick Setup (5 Minutes)

### Step 1: Get Free Groq API Key

1. Go to [Groq Console](https://console.groq.com/)
2. Click **"Sign Up"** (or log in if you have an account)
3. **No credit card required!** Just email signup
4. Go to **"API Keys"** section
5. Click **"Create API Key"**
6. Copy the key (starts with `gsk_...`)

### Step 2: Add to Render Environment Variables

1. Go to **Render** â†’ Your Service â†’ **Environment** tab
2. Add/Edit these variables:

   **LLM_PROVIDER**
   - Key: `LLM_PROVIDER`
   - Value: `groq`

   **GROQ_API_KEY**
   - Key: `GROQ_API_KEY`
   - Value: `gsk-your-actual-key-here` (paste your Groq key)

3. **Save** - Render will auto-redeploy (~1-2 minutes)

### Step 3: Test!

After redeploy, try generating a sprint plan. It should work **completely free!** ğŸ‰

---

## ğŸ“‹ Available Groq Models (All FREE!)

You can use any of these models (set `GROQ_MODEL` in Render):

- `llama-3.1-70b-versatile` (Recommended - most powerful)
- `llama-3.1-8b-instant` (Fastest)
- `mixtral-8x7b-32768` (Great for long contexts)
- `gemma-7b-it` (Google's model)

**Default:** `llama-3.1-70b-versatile` (already set)

---

## ğŸ”„ Comparison: Free Options

| Provider | Cost | Works on Render | Speed | Quality |
|----------|------|----------------|-------|---------|
| **Groq** | âœ… FREE | âœ… Yes | âš¡ Very Fast | â­â­â­â­â­ Excellent |
| Ollama | âœ… FREE | âŒ No (local only) | âš¡ Fast | â­â­â­â­ Good |
| OpenAI | ğŸ’° Paid | âœ… Yes | âš¡ Fast | â­â­â­â­â­ Excellent |
| Anthropic | ğŸ’° Paid | âœ… Yes | âš¡ Fast | â­â­â­â­â­ Excellent |

**Winner: Groq** - Free, fast, and works on Render! ğŸ†

---

## ğŸ¯ Recommended Setup

### For Render (Production):
```env
LLM_PROVIDER=groq
GROQ_API_KEY=gsk-your-key-here
GROQ_MODEL=llama-3.1-70b-versatile
```

### For Local Development:
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b-instruct
```

This way:
- **Render:** Uses Groq (free, cloud-based)
- **Local:** Uses Ollama (free, local)

---

## ğŸ“ Complete Render Environment Variables

Make sure you have these in Render:

### Required:
- `DATABASE_URL` - Your Supabase connection string
- `JWT_SECRET` - Secret key for JWT tokens
- `SECRET_KEY` - Another secret key
- `CORS_ORIGINS` - Your Vercel URL

### For FREE LLM (Groq):
- `LLM_PROVIDER=groq`
- `GROQ_API_KEY=gsk-...` (get from https://console.groq.com/keys)

---

## ğŸ†˜ Troubleshooting

### "GROQ_API_KEY is required"

**Solution:** Make sure you:
1. Got your API key from https://console.groq.com/keys
2. Added it to Render as `GROQ_API_KEY`
3. Set `LLM_PROVIDER=groq`
4. Saved and waited for redeploy

### Rate Limit Errors

**Groq free tier limits:**
- Very generous limits for development/testing
- If you hit limits, wait a few minutes and try again
- For production, consider upgrading (still very affordable)

### Still Getting Ollama Errors?

**Check:**
- `LLM_PROVIDER` is set to `groq` (not `ollama`)
- `GROQ_API_KEY` is set correctly
- Render has finished redeploying

---

## ğŸ‰ Summary

**You can now use AI-powered sprint planning 100% FREE!**

1. âœ… Get free Groq API key (no credit card)
2. âœ… Add to Render: `LLM_PROVIDER=groq` and `GROQ_API_KEY=...`
3. âœ… Save and wait for redeploy
4. âœ… Enjoy free AI sprint planning! ğŸš€

**No more token costs!** Groq's free tier is perfect for development and testing.

